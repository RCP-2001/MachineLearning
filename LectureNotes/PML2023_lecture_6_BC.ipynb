{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PML Lecture 6: The scheme of a machine learning program\n",
    "\n",
    "## Quick review\n",
    "\n",
    "1. Machine learning learns models from a set of **n observations (also known as sample, example, instance, record)** of data and then tries to predict **properties** of new data.\n",
    "2. Two categories: supervised learning and unsupervised learning\n",
    "3. Training and test stages. The primary goal of machine learning is to build model that generalizes to new data\n",
    "\n",
    "4. Learn machine learning basics \"An introduction to machine learning with scikit-learn\" from the tutorials at https://scikit-learn.org/stable/tutorial/index.html\n",
    "\n",
    "5. Learn the numpy array.\n",
    "    https://numpy.org/devdocs/user/quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "print(sk.__version__)\n",
    "#probably need to unpdate :(\n",
    "#dir(sk)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- Numpy Array\n",
    "- An example\n",
    "- What machine learning can do? (more examples) \n",
    "in\n",
    "- Machine learning algorithms--An overview\n",
    "\n",
    "- The scheme of a machine learning program\n",
    "\n",
    "- A simple machine algorithm\n",
    "\n",
    "- Paractise less basic operations of numpy array (After Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.22.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Iris Classification\n",
    "1. The 'Hello World!' task in machine learning: Iris classification\n",
    "The Iris dataset\n",
    "\n",
    "```python\n",
    "    import in.datasets as ds\n",
    "    iris = ds.load_iris()\n",
    "```\n",
    "    1. 150 observations; 3 different species, and 50 observations for each species.\n",
    "    2. 4 fearures:\n",
    "        - sepal length in cm\n",
    "        - sepal width in cm\n",
    "        - petal length in cm\n",
    "        - petal width in cm\n",
    "    3. Class labels (Species): Iris-Setosa, Iris-Versicolour, and Iris-Virginica\n",
    "![Figure 1: Machine Learning](Iris1-2.png)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "# explore the iris dataset\n",
    "import sklearn.datasets as ds\n",
    "\n",
    "iris = ds.load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'data_module',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# load data to numpy array\n",
    "data = iris.data\n",
    "tgts = iris.targetin #class Lables\n",
    "print(data.shape)\n",
    "print(tgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "# count the # of samples for each categories\n",
    "zero = one = two = 0\n",
    "#for loops are not what we want\n",
    "\n",
    "#for i in tgts:\n",
    "zero = (tgts == 0).sum() # comparison elements wise, returns an aray of true/false values\n",
    "one = (tgts == 1).sum()\n",
    "two = (tgts == 2).sum()\n",
    "print(zero, one, two)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What machine learning can do? (more examples)\n",
    "1. Example Day-to-Day Life \n",
    "    - Face ID and fingerprint ID\n",
    "    - Email Spam and Malware Filtering (ANN and Decision Tree algorithms) https://www.kaggle.com/c/email-spam/overview \n",
    "    - Product Recommendations, e.g., Netflix Prize https://en.wikipedia.org/wiki/Netflix_Prize \n",
    "    - Online custermer support, e.g., chatbot\n",
    "    - Search Engine Result Refining\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Advanced applications\n",
    "    - Video surveillance, e.g., critical locations monitoring, traffic monitoring, and wild fire early detection\n",
    "    - Self-Driving. https://carla.readthedocs.io/en/latest/cameras_and_sensors/#camera-semantic-segmentation\n",
    "    - Medical diagnosis, e.g., computer-aided diagnosis (CAD) systems. https://nihcc.app.box.com/v/DeepLesion\n",
    "    - Machine Translator\n",
    "    - Natural language processing. https://en.wikipedia.org/wiki/Natural_language_processing\n",
    "    - Fake banknote detection\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Do you have other examples/experience to share?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning algorithms--An overview\n",
    "\n",
    "1. Supervised learning\n",
    "    1. Regression. Linear regression (4), decision tree (5) and random forests (6), K-nearest neighbors (KNN)(1), Neural networks,...\n",
    "    2. Classification. K-nearest neighbors (KNN)(1), Logistic regression (2),Support Vector Machines (3), Neural networks (9), Convolutional neural networks (CNNS) (10)... \n",
    "    \n",
    "2. Unsupervised learning. K-means (7), spectral clustering (8), ...\n",
    "\n",
    "*The numbers in the parenthesis indicate the learning order of these algorithms in this class. we will move 9 and partial 10 to module 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The scheme of a machine learning program\n",
    "1. Data preparation\n",
    "2. Training\n",
    "3. Prediction and evaluation\n",
    "4. **Model persistence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Machine Learning\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#1. data preparation\n",
    "#1.1 load some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data # feature vectors\n",
    "y = iris.target # class labels\n",
    "\n",
    "#1.2. Split the data into a training set and a test set\n",
    "\n",
    "\n",
    "#2. model training: SVC: support vector classification\n",
    "\n",
    "#3. prediction and evaluation\n",
    "# 3.1 prediction\n",
    "\n",
    "\n",
    "#3.2 evaluation\n",
    "# error rate: # error output / toal # of samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predicted class labels for the test set\n",
    "\n",
    "\n",
    "## true class labels of the test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practise less basic operations of numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "[ 0  2  4  6  8 10 12 14 16 18]\n",
      "[0 4 8]\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "[1. 2. 3. 4. 5. 6.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [3., 3., 3.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basics\n",
    "import numpy as np\n",
    "\n",
    "# create\n",
    "arr = np.array([1, 2, 3], dtype = float)\n",
    "print(arr.dtype.name)\n",
    "arr1 = np.array([4, 5, 6], dtype = float)\n",
    "\n",
    "# element-wise operations\n",
    "arr + arr1\n",
    "arr * arr1\n",
    "arr - arr1\n",
    "\n",
    "#indexing by integers and slicing\n",
    "a = np.arange(10)*2\n",
    "print(a)\n",
    "print(a[0:6:2]) # 2 is the step\n",
    "\n",
    "# stack\n",
    "print(np.vstack((arr, arr1)))\n",
    "print(np.hstack((arr, arr1)))\n",
    "arr3 = np.vstack((arr, arr1))\n",
    "arr3 - arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5]\n",
      "4 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# less basics\n",
    "# indexing by arrays of integers and arrays of booleans\n",
    "lst = [1, 2, 3, 4, 5]\n",
    "print(lst[0::2])\n",
    "\n",
    "lst1 = np.array(lst)\n",
    "j = [0, 1, 2]\n",
    "lst1[j]\n",
    "\n",
    "j = [0, 0, 1, 2]\n",
    "lst1[j]\n",
    "\n",
    "# search the max values\n",
    "ind = lst1.argmax()\n",
    "print(ind, lst1[ind])\n",
    "\n",
    "#assign\n",
    "\n",
    "lst1[[0, 1, 2]] = -1\n",
    "lst1\n",
    "\n",
    "lst1>0\n",
    "lst1[lst1>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 4. 6.]\n",
      "[2. 4. 6.]\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting\n",
    "# deal with inputs that do not have exactly the same shape\n",
    "\n",
    "a = np.array([1.0, 2.0, 3.0])\n",
    "b = np.array([2.0, 2.0, 2.0])\n",
    "print(a * b)\n",
    "\n",
    "a = np.array([1.0, 2.0, 3.0])\n",
    "b = 2.0\n",
    "print(a * b)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "57a16ba939bf7798e81b9a35ecedcb3a18046e6c87d0faa8265892163afbc6b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
