{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SP23:CS 477/577: Python for Machine Learning\n",
    "\n",
    "### HW2: Use logistic regression for classification\n",
    "\n",
    "\n",
    "Student Name: Last, First"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preliminary\n",
    "\n",
    "#### 1.1 Problem formulation\n",
    "1. Training set. Data sampels: X_train = {$x_1, x_2, ..., x_i, ..., x_m$}. Target (class labels):Y_train = {$y_1, y_2, ..., y_i, ..., y_m$}\n",
    "    \n",
    "2. Predicted class probability in logistic regression:\n",
    "\n",
    "\\begin{equation*} \n",
    "    \\hat{y_i} = 1/(1+exp-(w_0 + w_1*x_{i,1} + ,..., +w_n*x_{i,n}))\n",
    "\\end{equation*}    \n",
    "    where $w_0, w_1,...,w_n$ are the linear model parameters, and $ x_{i,1}..., x_{i,n}$ are the features of the ith data feature vector $x_i$\n",
    "\n",
    "3. Cost/loss function of the logistic regression: the criterion to quantitatively evaluate how good the current model is (the less the better).\n",
    "\\begin{equation*}\n",
    "    J(w) = -C [\\sum_{i=1}^m (y_i \\times log(\\hat{y_i}) + (1-y_i) \\times log(1-\\hat{y_i}))] \n",
    "\\end{equation*}\n",
    "    - In the above equation, $\\hat{y_i}$  and  $y_i$ are the predicted class lable and the true class label of data sample $x_i$, respectively.\n",
    "    - P is the penalty/regularizer, and C controls the contribution of P. There are three typical options of P: L1 norm ($ \\|w\\|_1$), L2 norm ($\\frac{1}{2}w^T w$) and elstic-Net($\\frac{1 - \\rho}{2}w^T w + \\rho \\|w\\|_1$)\n",
    "    \n",
    "4. Model training is to use an 'optimization algorithm' to find the best $w$ that can minimize the loss function $J(w)$. Refer to the gradient descent algorithm in the Other Learning materials for more information.\n",
    "\n",
    "#### 1.2. The sklearn.linear_model.LogisticRegression class\n",
    "\n",
    "1. class introduction: Key attributes (e.g., C, and penalty)and methods (fit, predict, predict_proba, and score)\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#\n",
    "    \n",
    "2. source code\n",
    "    - https://github.com/scikit-learn/scikit-learn/blob/b194674c4/sklearn/linear_model/_logistic.py#L1191"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Breast Cancer Detection\n",
    "\n",
    "Develop the logistic regression approach to classify breast cases into malignat(cancer) and benign.\n",
    "\n",
    "Dataset\n",
    "\n",
    "    :Number of data samples: 569\n",
    "    :Number of features: 30 numeric. The first 10 features were directly calculated using mean feautues of all nuclei in an image\n",
    "    :Class labels (We changed the original class labels by using 1 - y.)\n",
    "        : Malignant: 1 (malignant or cancer)\n",
    "        : Benign: 0  (benign or non-cancer)  \n",
    "    https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n",
      "(569, 30) (569,)\n",
      "training samples (455, 30) test samples (114, 30)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as ds\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "# 1) data preparation\n",
    "X, y = ds.load_breast_cancer(return_X_y=True)\n",
    "y = 1-y\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "rs = 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=rs)\n",
    "print('training samples', X_train.shape, 'test samples', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Train and explore a logistic regression model. 25 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.70193886 -0.18897771  0.18942047 -0.02287614  0.14411881  0.19150739\n",
      "   0.37130293  0.20725414  0.26954863  0.03052996  0.04613319 -1.02791655\n",
      "   0.03333033  0.10636898  0.01239678 -0.04904355  0.02211939  0.02255294\n",
      "   0.03059153 -0.01346839 -0.26372385  0.41354888  0.19954951  0.0110381\n",
      "   0.25778885  0.68276195  1.22299877  0.44846203  0.62294273  0.0968387 ]]\n",
      "[[9.99605374e-01 3.94626224e-04]\n",
      " [9.66264322e-01 3.37356777e-02]\n",
      " [9.44933289e-01 5.50667111e-02]\n",
      " [9.99795932e-01 2.04068351e-04]\n",
      " [8.90069867e-01 1.09930133e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 1) train a logistic regression model. 5 points\n",
    "model = LogisticRegression(\n",
    "    random_state=rs, max_iter=3000).fit(X=X_train, y=y_train)\n",
    "\n",
    "\n",
    "# 2) print out the optimal model(linear) parameters after the training. 5 points\n",
    "# w0\n",
    "# w1...n\n",
    "params = model.coef_\n",
    "print(params)\n",
    "\n",
    "# 3) calculate and print out the predicted class probabilities of\n",
    "# the first 5 training samples by implementing the equation in 1.1 (y_i^hat). 10 points\n",
    "\n",
    "\n",
    "# 4) calculate and print out the predicted class probabilities of\n",
    "# the first 5 training samples using the predict_proba() function. 5 points\n",
    "probablity = model.predict_proba(X_train[:5])\n",
    "print(probablity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Evaluation 1.0. 25 points\n",
    "\n",
    "1) Accuracy. 5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9626373626373627\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# calculate and print out the accuracy of the trained model on the training set\n",
    "# using the score function\n",
    "print(model.score(X_train, y_train))\n",
    "\n",
    "\n",
    "# calculate and print out the accuracy of the trained model on the test set\n",
    "# using the score function\n",
    "print(model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Confusion matrix. 5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62  5]\n",
      " [ 1 46]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# print out the confusion matrix (cfm) for the trained model on the test set\n",
    "pred = model.predict(X_test)\n",
    "cfm = confusion_matrix(y_true=y_test, y_pred=pred)\n",
    "tn, fp, fn, tp = cfm.ravel()\n",
    "print(cfm)\n",
    "#\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) What is your observation from the cfm? 5 points\n",
    "\n",
    "Response (add your response here): \n",
    "\n",
    "   1) it tends to predicit benign when malignant more than maliganant when benign\n",
    "   \n",
    "   2) It has a pretty high overall accuracy\n",
    "   \n",
    "   ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Recall and Precision. 10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9787234042553191\n",
      "0.9019607843137255\n"
     ]
    }
   ],
   "source": [
    "# print out the recall ratio of the trained model for\n",
    "# detecting breast cancer using the above cfm\n",
    "Recall = (tp)/(tp+fn)\n",
    "print(Recall)\n",
    "\n",
    "# print out the precision of the trained model for\n",
    "# detecting breast cancer using the above cfm\n",
    "Precision = (tp)/(tp+fp)\n",
    "print(Precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.4 Evaluation 2.0. 30 points\n",
    "\n",
    "K-fold cross validation. (See Lecture Notes 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Why do we need K-fold cross validation in this application? 5 points\n",
    "\n",
    "    Reponse(add your response here):\n",
    "    \n",
    "    K-Fold will allow us to see how sensative our model is to changes in the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Use the 5-fold cross validation to re-evaluate a logistic regression model. 15 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy [0.90350877 0.92982456 0.90350877 0.95614035 0.92035398]\n",
      "recall [0.76744186 0.88372093 0.83333333 0.9047619  0.88095238]\n"
     ]
    }
   ],
   "source": [
    "# cross_validate in sklearn should be used in this task\n",
    "from sklearn.model_selection import cross_validate as cv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "myLR_1 = LogisticRegression(\n",
    "    C=5, penalty='l1', solver='saga', random_state=rs, max_iter=4000)\n",
    "\n",
    "# call the cross_validate function and set scoring = ('accuracy', 'recall')\n",
    "k = 5\n",
    "crossVal = cv(myLR_1, X, y, cv=k, scoring=('accuracy', 'recall'))\n",
    "\n",
    "# print out the test accuracy for each fold and print out the mean accuracy\n",
    "print(\"Accuracy\", crossVal[\"test_accuracy\"])\n",
    "\n",
    "# print out the test reacll ratios for each fold and print out the mean recall ratio\n",
    "print(\"recall\", crossVal[\"test_recall\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) What are the differences between Evaluation 1.0 and Evaluation 2.0? Which one is better for this application? and why? 10 points\n",
    "\n",
    "Response (Add your responses here):\n",
    "\n",
    "(1) Evaluation 2 Allows us to see many diffrent combanations of test and training data to show us how our model perfroms in a best case situation. \n",
    "\n",
    "(2) Evaluation 2 also allows to see how the model would be in a worst case situation\n",
    "\n",
    "...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.5 How can we improve the recall ratio?  20 points.\n",
    "\n",
    "Achieving high recall ratio(RR) is very important is cancer detection. Because RR indicates a model's ability to identify cancers; and low recall ratio may cost the lives of patients. Can you help improve the logistic regression approach to increse the recall ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy [0.93859649 0.93859649 0.97368421 0.94736842 0.96460177]\n",
      "recall [0.86046512 0.88372093 0.95238095 0.92857143 0.97619048]\n"
     ]
    }
   ],
   "source": [
    "# train a logistic regression model.\n",
    "\n",
    "# Changed solver to 'newton-cholesky'\n",
    "# changed penalty to 'l2'\n",
    "# improves both accuracy and recall rate\n",
    "myLR_2 = LogisticRegression(\n",
    "    C=5, penalty='l2', solver='newton-cholesky', random_state=rs, max_iter=4000)\n",
    "myLR_2.fit(X=X_train, y=y_train)\n",
    "\n",
    "# call the cross_validate function and set scoring = ('accuracy', 'recall')\n",
    "k = 5\n",
    "crossVal = cv(myLR_2, X, y, cv=k, scoring=('accuracy', 'recall'))\n",
    "\n",
    "# print out the test accuracy for each fold and print out the mean accuracy\n",
    "print(\"Accuracy\", crossVal[\"test_accuracy\"])\n",
    "\n",
    "# print out the test reacll ratios for each fold and print out the mean recall ratio\n",
    "print(\"recall\", crossVal[\"test_recall\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Print out the predicted probabilities of all misclassified samples (test set) and print out their class labels. 5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inccorect guess: 1\n",
      "[0.48036501 0.51963499]\n",
      "Inccorect guess: 1\n",
      "[0.37002772 0.62997228]\n",
      "Inccorect guess: 1\n",
      "[0.13756109 0.86243891]\n",
      "Inccorect guess: 1\n",
      "[0.40725988 0.59274012]\n",
      "Inccorect guess: 0\n",
      "[0.75600375 0.24399625]\n",
      "Inccorect guess: 1\n",
      "[0.2075175 0.7924825]\n"
     ]
    }
   ],
   "source": [
    "preds = myLR_2.predict(X_test)\n",
    "prob_preds = myLR_2.predict_proba(X_test)\n",
    "\n",
    "for i in range(preds.size ):\n",
    "    if(preds[i] != y_test[i]):\n",
    "        print(\"Inccorect guess:\", preds[i])\n",
    "        print(prob_preds[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Define a new prediction function that use threshod $th=0.37$ to determine the final class label (0 0r 1). 10 points\n",
    "\n",
    "Tips: if the predict_proba function returns a probability that is less than $th$ the new prediction function returns 0, otherwise returns 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "114\n",
      "[[65  2]\n",
      " [ 1 46]]\n"
     ]
    }
   ],
   "source": [
    "def myPredict(lr, X, th=0.35):\n",
    "    '''  \n",
    "        input:\n",
    "            lr: a trained logistic regression model\n",
    "            X: input feature vectors\n",
    "            th: threshold. \n",
    "\n",
    "        return predicted binary labels for all inuput samples\n",
    "    '''\n",
    "    probs = lr.predict_proba(X)\n",
    "    pred_b = np.empty(probs.size//2)\n",
    "\n",
    "    for i, pred in enumerate(probs):\n",
    "        if(pred[0] >= th):\n",
    "            pred_b[i] = 0\n",
    "        else:\n",
    "            pred_b[i] = 1\n",
    "\n",
    "    #\n",
    "    return pred_b\n",
    "\n",
    "\n",
    "y_pred = myPredict(myLR_2, X_test, th=0.35)\n",
    "print(y_pred.size)\n",
    "print(y_test.size)\n",
    "cm = confusion_matrix(y_true= y_test, y_pred= y_pred)\n",
    "print(cm)\n",
    "\n",
    "# print out the accuracy and the recall ratio on the test set\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Other possible ideas could be applied to improve the recall ratio of the logistic regression. 5 points\n",
    "\n",
    "Response:\n",
    "    We could probably change the solver to something better\n",
    "    modify the penalties\n",
    "    Change the threshold even more\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "17816603dc05db234063064a581facafe56897b7a0103b91884cec605ab64bc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
